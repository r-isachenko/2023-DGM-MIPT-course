{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRCQvjhe9FYV"
   },
   "source": [
    "# Homework5: Wasserstein GANs and GAN evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ptW8_Cp-0W6"
   },
   "source": [
    "## Task 1: Theory (3pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbg3n5qXZRWW"
   },
   "source": [
    "### Problem 1: Conjugate functions / f-GAN (1pt)\n",
    "\n",
    "We have discussed the framework for f-divergence minimization at Lecture 9. There we have got the variational inequality for f-divergence using Fenchel conjugate function:\n",
    "$$\n",
    "    D_f(\\pi || p) \\geq \\sup_{T \\in \\mathcal{T}} \\left[\\mathbb{E}_{\\pi}T(\\mathbf{x}) -  \\mathbb{E}_p f^*(T(\\mathbf{x})) \\right].\n",
    "$$\n",
    "Here\n",
    "$$\n",
    "\tf^*(t) = \\sup_{u \\in \\text{dom}_f} \\left( ut - f(u) \\right), \\quad f(u) = \\sup_{t \\in \\text{dom}_{f^*}} \\left( ut - f^*(t) \\right).\n",
    "$$\n",
    "\n",
    "In this task you have to derive standard GAN objective from the variational inequality.\n",
    "\n",
    "Let define function $f(u) = u \\log u - (u + 1) \\log (u + 1)$.\n",
    "\n",
    "- Find $\\text{dom}(f^*)$.\n",
    "- Show that $f^*(t) = - \\log (1 - e^t)$.\n",
    "- Use reparametrization $T(\\mathbf{x}) = \\log D(\\mathbf{x})$ to get the standard GAN objective (note that $D(\\mathbf{x}) \\in [0, 1]$, explain why this reparametrization is correct).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UIfd2ibZz-3"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-b1xWc1Z_ni"
   },
   "source": [
    "### Problem 1: Neural ODE vs backprop (2pt)\n",
    "\n",
    "At Lecture 10 we have discussed [Neural ODE](https://arxiv.org/pdf/1806.07366.pdf) model. There we used the adjoint state functions\n",
    "$$\n",
    "\t\\mathbf{a}_{\\mathbf{z}}(t) = \\frac{\\partial L(\\mathbf{y})}{\\partial \\mathbf{z}(t)}; \\quad \\mathbf{a}_{\\boldsymbol{\\theta}}(t) = \\frac{\\partial L(\\mathbf{y})}{\\partial \\boldsymbol{\\theta}(t)}.\n",
    "$$\n",
    "\n",
    "These two functions allowed to derive continuous version of backpropagation algorithm.\n",
    "\n",
    "The formulas for the method are given by Pontryagin theorem. It claims that\n",
    "$$\n",
    "\t\\frac{d \\mathbf{a}_{\\mathbf{z}}(t)}{dt} = - \\mathbf{a}_{\\mathbf{z}}(t)^T \\cdot \\frac{\\partial f_{\\boldsymbol{\\theta}}(\\mathbf{z}(t), t)}{\\partial \\mathbf{z}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{d \\mathbf{a}_{\\boldsymbol{\\theta}}(t)}{dt} = - \\mathbf{a}_{\\mathbf{z}}(t)^T \\cdot \\frac{\\partial f_{\\boldsymbol{\\theta}}(\\mathbf{z}(t), t)}{\\partial \\boldsymbol{\\theta}}.\n",
    "$$\n",
    "\n",
    "Your task here is to prove the first formula for $\\frac{d \\mathbf{a}_{\\mathbf{z}}(t)}{dt}$.\n",
    "\n",
    "**Hints**: you have to use 3 facts\n",
    "\n",
    "1. Notion of the limit:\n",
    "$$\n",
    "    \\frac{d \\mathbf{a}_{\\mathbf{z}}(t)}{dt} = \\lim_{\\varepsilon \\rightarrow +0} \\frac{\\mathbf{a}_{\\mathbf{z}}(t + \\varepsilon) - \\mathbf{a}_{\\mathbf{z}}(t)}{\\varepsilon}.\n",
    "$$\n",
    "\n",
    "2. Chain rule:\n",
    "$$\n",
    "    \\frac{\\partial L(\\mathbf{y})}{\\partial \\mathbf{z}(t)} = \\frac{\\partial L(\\mathbf{y})}{\\partial \\mathbf{z}(t + \\varepsilon)} \\cdot \\frac{\\mathbf{z}(t + \\varepsilon)}{\\partial \\mathbf{z}(t)}.\n",
    "$$\n",
    "3. Tailor series for\n",
    "$$\n",
    "    \\mathbf{z}(t + \\varepsilon) = \\int_{t}^{t + \\varepsilon} f_{\\boldsymbol{\\theta}}(\\mathbf{z}(t), t) d t + \\mathbf{z}(t).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_S_4rXazaCKS"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJQYtKgA5ate",
    "outputId": "30e69b84-7b6e-433f-99af-9c15ce0a090d"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "REPO_NAME = \"2023-DGM-MIPT-course\"\n",
    "!if [ -d {REPO_NAME} ]; then rm -Rf {REPO_NAME}; fi\n",
    "!git clone https://github.com/r-isachenko/{REPO_NAME}.git\n",
    "!cd {REPO_NAME}\n",
    "!pip install ./{REPO_NAME}/homeworks/\n",
    "!mv ./{REPO_NAME}/homeworks/stylegan.py ./stylegan.py\n",
    "!mv ./{REPO_NAME}/homeworks/inception.py ./inception.py\n",
    "!rm -Rf {REPO_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXhgRngvaed4"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import train_model, show_samples, plot_training_curves\n",
    "from dgm_utils import visualize_images, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVBow6mXafwx",
    "outputId": "29990fde-3581-4d26-f972-a17442a9e47c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn import functional as F\n",
    "from inception import InceptionV3\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "def reset_seed():\n",
    "    OUTPUT_SEED = 0xBADBEEF\n",
    "    torch.manual_seed(OUTPUT_SEED)\n",
    "    np.random.seed(OUTPUT_SEED)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "print(\"cuda is available:\", USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl59dviN5ekr"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import show_samples, plot_training_curves\n",
    "from dgm_utils import visualize_images, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftMgDK_cPFmD"
   },
   "outputs": [],
   "source": [
    "# do not change this function\n",
    "def plot_losses(losses: np.ndarray, title: str):\n",
    "    n_itr = len(losses)\n",
    "    xs = np.arange(n_itr)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(xs, losses)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Iterations\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8klUHHmAjHsI"
   },
   "source": [
    "## Task 2: Wasserstein GANs for CIFAR 10 (5pt)\n",
    "\n",
    "In this task you will fit different kinds of Wasserstein GANs (different ways to enforce Lipschitzness) that we discussed in the Lecture 8 to the CIFAR10 dataset\n",
    "* [WGAN](https://arxiv.org/abs/1701.07875) - standard Wasserstein GAN with weight clipping;\n",
    "* [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf) - Wasserstein GAN with Gradient Penalty;\n",
    "* [SN-GAN](https://arxiv.org/pdf/1802.05957.pdf) - Wasserstein GAN with Spectral Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "dAvSLXlKZ5q7",
    "outputId": "939f0643-92b4-4d37-b1af-4e8a4b00b16d"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"CIFAR10 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PnfAHgw32Hr"
   },
   "source": [
    "### Problem 1: WGAN (2pt)\n",
    "\n",
    "[WGAN](https://arxiv.org/abs/1701.07875) model uses weight clipping to enforce Lipschitzness of the critic.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "\\min_{G} W(\\pi || p) \\approx \\min_{G} \\max_{\\boldsymbol{\\phi} \\in \\boldsymbol{\\Phi}} \\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} f_{\\boldsymbol{\\phi}}(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{z})} f_{\\boldsymbol{\\phi}}(G_{\\boldsymbol{\\theta}}(\\mathbf{z}))\\right].\n",
    "$$\n",
    "Here $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$ is the critic model. The critic weights $\\boldsymbol{\\phi}$ should lie in the compact set $\\boldsymbol{\\Phi} = [-c, c]^d$.\n",
    "\n",
    "In this task we will use fully-connected networks for the generator $G_{\\boldsymbol{\\theta}}(\\mathbf{z})$ and the critic $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc9WGmMMkxTU"
   },
   "source": [
    "Here we will use convolution-based generator and critic.\n",
    "\n",
    "First of all, let define generator network. It will be the same for all WGAN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a7fjcx0vL8R"
   },
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, input_size: int = 128, n_channels: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.input_size = input_size\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) define linear layer with output units 4 * 4 * 4 * n_channels, then relu\n",
    "        # 2) define transposed conv with stride 2, kernel size 2 then BN, then relu\n",
    "        # 3) define transposed conv with stride 2, kernel size 2\n",
    "    \n",
    "        # ====\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all layers\n",
    "\n",
    "        # ====\n",
    "        return output.view(-1, 3, 32, 32)\n",
    "\n",
    "    def sample(self, n_samples: int) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from standard normal distribution and apply the model\n",
    "        \n",
    "        # ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uVbwHvAruFh"
   },
   "source": [
    "Now it is time to define our critic. Here we will use the same class for all WGAN models, but the arguments will depend on the WGAN mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFA0tI7ZrloP"
   },
   "outputs": [],
   "source": [
    "class ConvCritic(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels: int,\n",
    "        conv_layer: Optional[object] = None,\n",
    "        linear_layer: Optional[object] = None,\n",
    "        clip_c: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.conv_layer = conv_layer or nn.Conv2d\n",
    "        self.linear_layer = linear_layer or nn.Linear\n",
    "        self.clip_c = clip_c\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # sequence of convolutional layers and LeakyRelU -> reshape -> FC\n",
    "        # !Note:! use self.conv_layer and self.linear_layer\n",
    "        # (it is important for the SN-GAN model)\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def clip_weights(self) -> None:\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "                # ====\n",
    "                # your code\n",
    "                # clip the weight to the range [-clip_c, clip_c]\n",
    "                \n",
    "                # ====\n",
    "                layer.weight.data = weight\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) clip the critic weights (if clip_c is given)\n",
    "        # 2) apply all layers\n",
    "        \n",
    "        # ====\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDi02jfKAVN-"
   },
   "outputs": [],
   "source": [
    "def train_wgan(\n",
    "    generator: object,\n",
    "    critic: object,\n",
    "    train_loader: object,\n",
    "    critic_steps: int,\n",
    "    batch_size: int,\n",
    "    n_epochs: int,\n",
    "    lr: float,\n",
    "    use_cuda: bool = False,\n",
    "    gp_weight: Optional[float] = None,\n",
    ") -> dict:\n",
    "\n",
    "    if use_cuda:\n",
    "        critic = critic.cuda()\n",
    "        generator = generator.cuda()\n",
    "    critic.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    curr_iter = 0\n",
    "    d_loss, g_loss = torch.zeros(1), torch.zeros(1)\n",
    "    batch_loss_history = {\"discriminator_losses\": [], \"generator_losses\": []}\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        for batch_i, x in enumerate(train_loader):\n",
    "            curr_iter += 1\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "            # do a critic update\n",
    "            critic_optimizer.zero_grad()\n",
    "            fake_data = generator.sample(x.shape[0])\n",
    "\n",
    "            # ====\n",
    "            # your code\n",
    "            # D(x_fake) - D(x_real)\n",
    "            \n",
    "            # ====\n",
    "\n",
    "            if gp_weight is not None:\n",
    "                gp = gradient_penalty(critic, x, fake_data)\n",
    "                d_loss += gp_weight * gp\n",
    "\n",
    "            d_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            # generator update\n",
    "            if curr_iter % critic_steps == 0:\n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_data = generator.sample(batch_size)\n",
    "                # ====\n",
    "                # your code\n",
    "                # -D(x_fake)\n",
    "                \n",
    "                # ====\n",
    "                g_loss.backward()\n",
    "                gen_optimizer.step()\n",
    "\n",
    "                batch_loss_history[\"generator_losses\"].append(g_loss.data.cpu().numpy())\n",
    "                batch_loss_history[\"discriminator_losses\"].append(\n",
    "                    d_loss.data.cpu().numpy()\n",
    "                )\n",
    "\n",
    "    return batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "70d3ba49645049e39b4788ca2824abec",
      "91fd48b2c517440ab78e1408b78a6610",
      "97a21761bf48493e9df150cd0c092ee3",
      "2fde761fbb244952823d91172be573b7",
      "5a68715ee62345fb92e472162e8d6853",
      "46679df9cef2458e8d9f89ca48b8bb1e",
      "30c80e78c1c94e1d82ce19f0c387918b",
      "9ea1673c51134ece8227b0eeb2cdefd9",
      "0a27a6a947b9464687ab7bbec5c2587c",
      "6f59289c9d9f442d894ff6538950dc2a",
      "acaed6a5659845e7bb0d1e311a28e014"
     ]
    },
    "id": "bjOGNNU59Fr_",
    "outputId": "2c111286-b65e-47cb-a3c9-bfd8145053c7"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters (you have to train the model more than 20 epochs to get good results)\n",
    "BATCH_SIZE =     # any adequate value\n",
    "N_CHANNELS =     # > 32\n",
    "N_EPOCHS =       # > 10\n",
    "CRITIC_STEPS =   # > 2\n",
    "CLIP_C =         # < 1\n",
    "LR =             # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS, clip_c=CLIP_C)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    use_cuda=USE_CUDA,\n",
    ")\n",
    "\n",
    "plot_losses(train_losses[\"discriminator_losses\"], \"Discriminator loss\")\n",
    "plot_losses(train_losses[\"generator_losses\"], \"Generator loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2oddhso98hq"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "EXWKEKxQ9_DH",
    "outputId": "30276c52-2ae5-49ff-80d1-2cd1537d5e93"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "show_samples(samples[:100], title=\"CIFAR-10 WGAN-generated samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG4ErQLNjZr9"
   },
   "source": [
    "### Problem 2: WGAN-GP for CIFAR 10 (1pt)\n",
    "\n",
    "[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)  model uses gradient penalty to enforce Lipschitzness.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "    W(\\pi || p) = \\underbrace{\\mathbb{E}_{\\pi(\\mathbf{x})} f_{\\boldsymbol{\\phi}}(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{x} | \\boldsymbol{\\theta})} f_{\\boldsymbol{\\phi}}(\\mathbf{x})}_{\\text{original critic loss}} + \\lambda \\underbrace{\\mathbb{E}_{U[0, 1]} \\left[ \\left( \\| \\nabla_{\\hat{\\mathbf{x}}} f_{\\boldsymbol{\\phi}}(\\hat{\\mathbf{x}}) \\|_2 - 1 \\right) ^ 2\\right]}_{\\text{gradient penalty}},\n",
    "$$\n",
    "where the samples $\\hat{\\mathbf{x}}_t = t \\mathbf{x} + (1 - t) \\mathbf{y}$ with $t \\in [0, 1]$ are uniformly sampled along straight lines between pairs of points: $\\mathbf{x}$ from the data distribution $\\pi(\\mathbf{x})$ and $\\mathbf{y}$ from the generator distribution $p(\\mathbf{x} | \\boldsymbol{\\theta}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aTCJKgoAuUm"
   },
   "source": [
    "Let define our gradient penalty loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RXJ6autArvg"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(\n",
    "    critic: object, real_data: torch.Tensor, fake_data: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    batch_size = real_data.shape[0]\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # Calculate interpolation x_t = t * x_real + (1 - t) x_fake\n",
    "    # 1) sample t\n",
    "    # 2) create x_t (be careful about shapes)\n",
    "    # 3) apply critic to x_t\n",
    "    \n",
    "    # ====\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_output,\n",
    "        inputs=x_t,\n",
    "        grad_outputs=torch.ones(d_output.size()).to(fake_data.device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.reshape(batch_size, -1)\n",
    "    # ====\n",
    "    # your code\n",
    "    # compute gradient norm\n",
    "    \n",
    "    # ====\n",
    "    return ((gradients_norm - 1) ** 2).mean()\n",
    "\n",
    "\n",
    "def test_gradient_penalty():\n",
    "    x = np.random.normal(size=(10, 4))\n",
    "    x_norm = np.mean(np.sqrt(x**2))\n",
    "    x = torch.randn(size=(10, 4))\n",
    "    x.requires_grad = True\n",
    "    assert gradient_penalty(lambda x: x, x, x).numpy() == 1\n",
    "    assert gradient_penalty(lambda x: x * 0, x, x).numpy() == 1\n",
    "\n",
    "\n",
    "test_gradient_penalty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBRZJXGAryNA"
   },
   "source": [
    "That is all :)\n",
    "\n",
    "We will use the same `ConvGenerator`, `ConvCritic` and `train_wgan()` as for WGAN model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "52adbf79e43e4a75812b1971e1ec42c4",
      "a0bb17fd40394cf780c5f3ab7d50e67f",
      "39371959124c45d6b23ed4c396786b2d",
      "5843f6c63f3447309428dddfee56cfeb",
      "5edbc7bb89844306bedd81f02822ebd0",
      "ea309d7a822141ef862de2080e315fd0",
      "47b504291ac142c6810d2455e7ba640b",
      "935f5c3aed5b45589fadd155c39398ef",
      "161ea9dc2761433d9b09475393a619cf",
      "83f883cda4a54d2080a7eb688c6dde5c",
      "1d7c451931d946e0b4ac2acd87c14a69"
     ]
    },
    "id": "aY6qzJ5MSuiX",
    "outputId": "6803456d-48ee-47d6-e609-8793f8b30d08"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters (you have to train the model more than 20 epochs to get good results)\n",
    "BATCH_SIZE =     # any adequate value\n",
    "N_CHANNELS =     # > 32\n",
    "N_EPOCHS =       # > 10\n",
    "CRITIC_STEPS =   # > 2\n",
    "GP_WEIGHT =      # > 5\n",
    "LR =             # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    use_cuda=USE_CUDA,\n",
    ")\n",
    "\n",
    "plot_losses(train_losses[\"discriminator_losses\"], \"Discriminator loss\")\n",
    "plot_losses(train_losses[\"generator_losses\"], \"Generator loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unAqs_pEs59l"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "8I0pNzHchqRs",
    "outputId": "1b8e1dad-320e-47a9-9113-08c6de8bbf38"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "show_samples(samples[:100], title=\"CIFAR-10 WGAN-GP-generated samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-YPxpeDDCU9"
   },
   "source": [
    "### Problem 3: SN-GAN on CIFAR10 (2pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvbrtdFgBTfE"
   },
   "source": [
    "[Spectral Normalization GAN](https://arxiv.org/pdf/1802.05957.pdf) replaces the weights in the critic $f_{\\boldsymbol{\\phi}}(\\mathbf{x})$ by\n",
    "$$\n",
    "    \\mathbf{W}^{SN} = \\frac{\\mathbf{W}}{\\|\\mathbf{W}\\|_2}.\n",
    "$$\n",
    "\n",
    "This ensures that $\\| f\\|_L \\leq 1.$.\n",
    "\n",
    "Power iteration method allows to efficiently compute $\\| \\mathbf{W} \\|_2 = \\sqrt{\\lambda_{\\text{max}}(\\mathbf{W}^T \\mathbf{W})}$.\n",
    "    \n",
    "The pseudocode of the method is:\n",
    "* $\\mathbf{u}_0$ -- random vector.\n",
    "* for $k = 0, \\dots, n - 1$:\n",
    "$$\n",
    "    \\mathbf{v}_{k+1} = \\frac{\\mathbf{W}^T \\mathbf{u}_{k}}{\\| \\mathbf{W}^T \\mathbf{u}_{k} \\|}, \\quad \\mathbf{u}_{k+1} = \\frac{\\mathbf{W} \\mathbf{v}_{k+1}}{\\| \\mathbf{W} \\mathbf{v}_{k+1} \\|}.\n",
    "$$\n",
    "* approximate the spectral norm\n",
    "$$\n",
    "    \\| \\mathbf{W} \\|_2 = \\sqrt{\\lambda_{\\text{max}}(\\mathbf{W}^T \\mathbf{W})} \\approx \\mathbf{u}_{n}^T \\mathbf{W} \\mathbf{v}_{n}.\n",
    "$$\n",
    "\n",
    "First step is to implement this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-Q1099aBUhF"
   },
   "outputs": [],
   "source": [
    "def power_iteration_method(\n",
    "    W: torch.Tensor,\n",
    "    n_iters: int,\n",
    "    u_init: Optional[nn.Parameter] = None,\n",
    "    v_init: Optional[nn.Parameter] = None,\n",
    ") -> tuple:\n",
    "    if u_init is None:\n",
    "        u_init = nn.Parameter(torch.randn(W.shape[0]), requires_grad=False)\n",
    "    if v_init is None:\n",
    "        v_init = nn.Parameter(torch.randn(W.shape[1]), requires_grad=False)\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # 1) implement for loop and update v_init/u_init\n",
    "    # 2) calculate spectral norm\n",
    "    # 3) return spectral norm (sigma) and the last values for v_init, u_init\n",
    "\n",
    "    # ====\n",
    "    return sigma, u_init, v_init\n",
    "\n",
    "\n",
    "def test_power_iteration_method():\n",
    "    W = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]], dtype=np.float32)\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "    W_tensor = torch.tensor(W)\n",
    "    sigma, u, v = power_iteration_method(W_tensor, n_iters=10)\n",
    "    np.allclose(S[0], sigma)\n",
    "    np.allclose(u, U[:, 0])\n",
    "    np.allclose(v, V[0, :])\n",
    "\n",
    "\n",
    "test_power_iteration_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skqXws_UBYtn"
   },
   "source": [
    "Now we need to define layers with Spectral Normalization (we will use `SpectralNormConv2D` and `SpectralNormLinear` layers instead of standard `nn.Conv2D` and `nn.Linear` in our critic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3davuPNBZFp"
   },
   "outputs": [],
   "source": [
    "class SpectralNormConv2D(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.power_iterations = kwargs.pop(\"power_iterations\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.u = nn.Parameter(torch.randn(self.weight.shape[0]), requires_grad=False)\n",
    "        self.v = nn.Parameter(torch.randn(self.weight.shape[1]), requires_grad=False)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        W = self.weight.view(self.weight.shape[0], -1)\n",
    "        with torch.no_grad():\n",
    "            # ====\n",
    "            # your code\n",
    "            # apply power iteration method\n",
    "\n",
    "            # ====\n",
    "        self.u.data = u.data\n",
    "        self.v.data = v.data\n",
    "        self.weight.data = self.weight.data / sigma\n",
    "\n",
    "        return super().forward(input)\n",
    "\n",
    "\n",
    "class SpectralNormLinear(nn.Linear):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.power_iterations = kwargs.pop(\"power_iterations\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.u = nn.Parameter(torch.randn(self.weight.shape[0]), requires_grad=False)\n",
    "        self.v = nn.Parameter(torch.randn(self.weight.shape[1]), requires_grad=False)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        W = self.weight.view(self.weight.shape[0], -1)\n",
    "        with torch.no_grad():\n",
    "            # ====\n",
    "            # your code\n",
    "            # apply power iteration method\n",
    "\n",
    "            # ====\n",
    "        self.u.data = u.data\n",
    "        self.v.data = v.data\n",
    "        self.weight.data = self.weight.data / sigma\n",
    "\n",
    "        return super().forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmolmRfl-Ysb"
   },
   "source": [
    "That is all :)\n",
    "\n",
    "We will use the same `ConvGenerator`, `ConvCritic` and `train_wgan()` as for WGAN model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c74150b42e2b4f7b9954acff3f7c7db2",
      "d05d064e93e04b5e85ccea618bfd44de",
      "441cc3087298473f845a472ec3b433fa",
      "375467f9c01c46a3bb200f471c04387c",
      "65b5df8489aa40748b6ea20e6fb9b19d",
      "f4d76da3a8f44c9b96a8835730dab334",
      "d2280cc997464b608898a04cce98c617",
      "7d21ad6973864ad99b8138837abf07b7",
      "a83a2a5e683245a6b2f6b4317ba088bc",
      "60e85ebf0dc54d95aeca4bd64565e30a",
      "ff4e4d56637c49c9af31f385f8c3efa0"
     ]
    },
    "id": "LOTPsSRkBnj4",
    "outputId": "ed3d4e3c-106e-4429-beeb-1bb2b484834d"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE =         # any adequate value\n",
    "DIM =                # > 32\n",
    "N_EPOCHS =           # > 20\n",
    "CRITIC_STEPS =       # 1 < x < 10\n",
    "POWER_ITERATIONS =   # 1 < x < 5\n",
    "LR =                 # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(\"Total number of epochs:\", N_EPOCHS)\n",
    "\n",
    "generator = ConvGenerator(n_channels=DIM)\n",
    "conv_layer = partial(SpectralNormConv2D, power_iterations=POWER_ITERATIONS)\n",
    "linear_layer = partial(SpectralNormLinear, power_iterations=POWER_ITERATIONS)\n",
    "critic = ConvCritic(n_channels=DIM, conv_layer=conv_layer, linear_layer=linear_layer)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator,\n",
    "    critic,\n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    use_cuda=USE_CUDA,\n",
    ")\n",
    "\n",
    "g_losses = train_losses[\"generator_losses\"]\n",
    "d_losses = train_losses[\"discriminator_losses\"]\n",
    "\n",
    "plot_losses(g_losses, \"Generator loss\")\n",
    "plot_losses(d_losses, \"Discriminator loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "JbOGh6mYBpxu",
    "outputId": "1b012c69-7b4e-405b-e92a-bf605b429737"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "show_samples(samples[:100], title=\"CIFAR-10 generated samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqk96UWO-7eZ"
   },
   "source": [
    "You are really welcome to experiment with combination of three approaches to get best samples :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1VlsYZxahzg"
   },
   "source": [
    "## Task 3: Inception Score and FID (5pt)\n",
    "\n",
    "Here our goal is to understand how to evaluate likelihood-free models using [Inception Score](https://arxiv.org/pdf/1606.03498.pdf) and [Frechet Inception Distance](https://arxiv.org/pdf/1706.08500.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mhhPc1kai3i"
   },
   "outputs": [],
   "source": [
    "# this is a helper function that we will use further\n",
    "def resize_tensor(x: torch.Tensor, image_size: int) -> torch.Tensor:\n",
    "    return F.interpolate(\n",
    "        x, size=(image_size, image_size), mode=\"bilinear\", align_corners=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwJA54t1anB5"
   },
   "source": [
    "Your task is to implement the *Inception score* and *FID* score and estimate the quality of two trained *StyleGAN* models we have discussed on Seminar 9 and Seminar 10:\n",
    "\n",
    "1. `stylegan_wgangp` is a *StyleGAN* model trained with *WGAN-GP* loss on CIFAR10 dataset ([ckpt_link](https://drive.google.com/file/d/1bTDbmleLXowuGcahsoSBeihSVbGgW52X/view?usp=sharing))\n",
    "\n",
    "2. `stylegan_r1` is a *StyleGAN* model trained with standard gan loss with $R_1$ regularization on CIFAR10 dataset ([ckpt_link](https://drive.google.com/file/d/1PNeESbetxazQkBJbBnoizyWgGKJwfpW5/view?usp=sharing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92lCY5Y0aoOk",
    "outputId": "62e7fc82-f19f-46b1-b07e-617043c2c9dd"
   },
   "outputs": [],
   "source": [
    "# loading models checkpoints\n",
    "!gdown --id 1bTDbmleLXowuGcahsoSBeihSVbGgW52X\n",
    "!gdown --id 1PNeESbetxazQkBJbBnoizyWgGKJwfpW5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVdby-Hkap-J",
    "outputId": "b3b38a0c-f8fb-4bae-a905-13c3e7a76ffe"
   },
   "outputs": [],
   "source": [
    "from stylegan import MicroStyleGANGenerator\n",
    "from copy import deepcopy\n",
    "\n",
    "sg_wgangp_name = \"stylegan_wgangp_loss_FINAL.pth\"\n",
    "sg_gan_r1_name = \"stylegan_gan_r1_loss_FINAL.pth\"\n",
    "\n",
    "\n",
    "stylegan_wgangp = MicroStyleGANGenerator(\n",
    "    z_dim=128,\n",
    "    map_hidden_dim=256,\n",
    "    w_dim=64,\n",
    "    in_chan=64,\n",
    "    out_chan=3,\n",
    "    kernel_size=3,\n",
    "    hidden_chan=32,\n",
    ")\n",
    "\n",
    "stylegan_r1 = deepcopy(stylegan_wgangp)\n",
    "\n",
    "stylegan_wgangp.load_state_dict(\n",
    "    torch.load(\"./{}\".format(sg_wgangp_name), map_location=\"cpu\")[\"generator\"]\n",
    ")\n",
    "\n",
    "stylegan_r1.load_state_dict(\n",
    "    torch.load(\"./{}\".format(sg_gan_r1_name), map_location=\"cpu\")[\"generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phZS-ESMar61"
   },
   "source": [
    "Let's look at model samples from `stylegan_r1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "iOS0EkE3asNK",
    "outputId": "d5cf1330-1cc5-4d2f-d626-81c68021d3a5"
   },
   "outputs": [],
   "source": [
    "batch = stylegan_r1.sample(100).detach().cpu().numpy()\n",
    "show_samples(batch, \"CIFAR10 samples, shape = ({0}, {0})\".format(32), nrow=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11l8BP97avOn"
   },
   "source": [
    "Let's look at model samples from `stylegan_wgangp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "hZB6-Jgfavq8",
    "outputId": "ac68bfd5-734f-4630-c7ff-bde568697c73"
   },
   "outputs": [],
   "source": [
    "batch = stylegan_wgangp.sample(100).detach().cpu().numpy()\n",
    "show_samples(batch, \"CIFAR10 samples, shape = ({0}, {0})\".format(32), nrow=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT34n2CYayMR"
   },
   "source": [
    "###  Inception Score\n",
    "\n",
    "The formula for Inception Score is\n",
    "$$\n",
    "    \\text{IS} = \\exp \\bigl( \\mathbb{E}_{\\mathbf{x}} KL(p(y | \\mathbf{x}) || p(y)) \\bigr),\n",
    "$$\n",
    "\n",
    "where\n",
    "* $p(y | \\mathbf{x})$ is a pretrained classification model with labels $y$ (we will use [Inception V3 model](https://pytorch.org/vision/main/generated/torchvision.models.inception_v3.html));\n",
    "* $p(y) = \\int p(y | \\mathbf{x}) p(\\mathbf{x}) d \\mathbf{x}$ is a marginal distribution on labels.\n",
    "\n",
    "In order to calculate the **Inception** score we will use `InceptionV3` last layer activations (those before computing `Softmax`). The dimensionality of these activations is $1008$.\n",
    "\n",
    "Let initialize our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8RaiX6Aa0k-",
    "outputId": "c3ca7a66-97ef-4d40-b80b-507a8429f2ff"
   },
   "outputs": [],
   "source": [
    "DIMS = 1008\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[DIMS]\n",
    "inception_model_act5 = InceptionV3([block_idx])\n",
    "if USE_CUDA:\n",
    "    inception_model_act5 = inception_model_act5.cuda()\n",
    "inception_model_act5.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WFYLKbea3QD"
   },
   "source": [
    "We need to get class probabilities from our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjETtL1Ua3hO"
   },
   "outputs": [],
   "source": [
    "def get_inception_probs(x: torch.Tensor, model: object) -> np.ndarray:\n",
    "    # ====\n",
    "    # your code\n",
    "    # apply model and get probs (apply softmax)\n",
    "\n",
    "    # ====\n",
    "    return probs.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def test_get_inception_probs():\n",
    "    x = torch.zeros(size=(1, 3, 10, 10))\n",
    "    if USE_CUDA:\n",
    "        x = x.cuda()\n",
    "    probs = get_inception_probs(x, inception_model_act5)\n",
    "    true_probs = np.array(\n",
    "        [\n",
    "            0.00012616384,\n",
    "            0.00031305864,\n",
    "            0.00019984621,\n",
    "            0.00024997862,\n",
    "            0.00005619833,\n",
    "            0.00010180601,\n",
    "            0.00002303111,\n",
    "            0.0001946776,\n",
    "            0.0015921608,\n",
    "            0.000064336535,\n",
    "        ]\n",
    "    )\n",
    "    assert np.allclose(probs[0, :10], true_probs)\n",
    "\n",
    "\n",
    "test_get_inception_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYSh_Kcoa8Wq"
   },
   "outputs": [],
   "source": [
    "# this is a helper function that generates samples from the StyleGAN generator\n",
    "def generate_fake_images_stylegan(\n",
    "    sg_generator: object, n_samples: int, batch_size: int\n",
    ") -> np.ndarray:\n",
    "    fake_images = []\n",
    "    for i in range(n_samples // batch_size):\n",
    "        fake_samples = sg_generator.sample(batch_size).cpu().detach().numpy()\n",
    "        fake_images.extend(fake_samples)\n",
    "\n",
    "    fake_samples = sg_generator.sample(n_samples % batch_size).cpu().detach().numpy()\n",
    "    fake_images.extend(fake_samples)\n",
    "    return np.array(fake_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haDxeuSva-DE"
   },
   "source": [
    "It is the main function for getting Inception Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dldd3P3ma-Rt"
   },
   "outputs": [],
   "source": [
    "def get_inception_score(\n",
    "    generator: object,\n",
    "    inception_model: object,\n",
    "    n_samples: int,\n",
    "    batch_size: int = 32,\n",
    "    splits: int = 10,\n",
    ") -> np.ndarray:\n",
    "    if USE_CUDA:\n",
    "        generator = generator.cuda()\n",
    "        inception_model = inception_model.cuda()\n",
    "\n",
    "    generator.eval()\n",
    "    inception_model.eval()\n",
    "\n",
    "    fake_images = generate_fake_images_stylegan(generator, n_samples, batch_size)\n",
    "    loader = torch.utils.data.DataLoader(fake_images, batch_size=batch_size)\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # get probs of size [n_samples x 1000] for the fake_samples\n",
    "\n",
    "    # ====\n",
    "\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = probs[k * (n_samples // splits) : (k + 1) * (n_samples // splits), :]\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) calculate p_y mean value of the current part\n",
    "        # 2) calculate KL (use could you entropy function from scipy)\n",
    "        # 3) exponentiate it\n",
    "\n",
    "        # ====\n",
    "        split_scores.append(split_score)\n",
    "\n",
    "    return np.mean(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lQa2qDpbCAE"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "BATCH_SIZE = 16\n",
    "SPLITS = 5\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "IS_stylegan_r1 = get_inception_score(\n",
    "    generator=stylegan_r1,\n",
    "    inception_model=inception_model_act5,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    splits=SPLITS,\n",
    ")\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "IS_stylegan_wgangp = get_inception_score(\n",
    "    generator=stylegan_wgangp,\n",
    "    inception_model=inception_model_act5,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    splits=SPLITS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iktQHlPbDn5"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(IS_stylegan_r1, 6.566, atol=0.1)\n",
    "assert np.allclose(IS_stylegan_wgangp, 6.63, atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFfxMON_bF2k"
   },
   "source": [
    "**In case you have free time**: You are free to evaluate the models from the previous homework via Inception-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IC7Y2RpbGGs"
   },
   "outputs": [],
   "source": [
    "# Inception scores of your nice models which beat StyleGAN\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnzazethbI40"
   },
   "source": [
    "###  Frechet Inception Distance\n",
    "\n",
    "Now we will implement Frechet Inception Distance:\n",
    "\n",
    "$$\n",
    "\t\\text{FID} (\\pi, p) = \\| \\mathbf{m}_{\\pi} - \\mathbf{m}_{p}\\|_2^2 + \\text{Tr} \\left( \\boldsymbol{\\Sigma}_{\\pi} + \\boldsymbol{\\Sigma}_p - 2 \\sqrt{\\boldsymbol{\\Sigma}_{\\pi} \\boldsymbol{\\Sigma}_p} \\right)\n",
    "$$\n",
    "\n",
    "* Representations are the outputs of the intermediate layer from the pretrained classification model (we will use the activations of the last by one layer of `InceptionV3` (which have dimensionality $(2048, 1, 1)$), that's why the last two dimensions should be dropped before FID statistics calculation).\n",
    "* $\\mathbf{m}_{\\pi}$, $\\boldsymbol{\\Sigma}_{\\pi} $ are the mean vector and the covariance matrix of feature representations for samples from $\\pi(\\mathbf{x})$\n",
    "* $\\mathbf{m}_{p}$, $\\boldsymbol{\\Sigma}_p$ are the mean vector and the covariance matrix of feature representations for samples from $p(\\mathbf{x} | \\boldsymbol{\\theta})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkSozHiPbLn_"
   },
   "source": [
    "Let initialize our classification model which outputs last by one activations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOpHVjNvbJKv",
    "outputId": "96fb6c64-dbd8-4442-9e38-aaadaa80b446"
   },
   "outputs": [],
   "source": [
    "DIMS = 2048\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[DIMS]\n",
    "inception_model_act4 = InceptionV3([block_idx])\n",
    "if USE_CUDA:\n",
    "    inception_model_act4 = inception_model_act4.cuda()\n",
    "inception_model_act4.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivz41HqxbOn7"
   },
   "source": [
    "Here we need samples from the ground truth distribution $\\pi(\\mathbf{x})$ (CIFAR10 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "MHjFiT6kbOy2",
    "outputId": "b0aea12a-ec49-4c78-ae46-1d8660196ce7"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"CIFAR10 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2giG0jJxbRWG"
   },
   "source": [
    "Let implement function to take square root of matrix (we need it for the formula above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_REm_GjfbRsX"
   },
   "outputs": [],
   "source": [
    "# this is a helper function, do not change\n",
    "def get_matrix_sqrt(x: torch.Tensor) -> torch.Tensor:\n",
    "    y = x.cpu().detach().numpy()\n",
    "    y = scipy.linalg.sqrtm(y)\n",
    "    if not np.isfinite(y).all():\n",
    "        print(\"bad!\")\n",
    "    return torch.Tensor(y.real, device=x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO0qh5StbVwQ"
   },
   "source": [
    "Not let implement the function to calculate the distance (it is just the formula above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R4Ed1v-bWJk"
   },
   "outputs": [],
   "source": [
    "def get_distance(\n",
    "    mu_x: torch.Tensor, mu_y: torch.Tensor, sigma_x: torch.Tensor, sigma_y: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    # ====\n",
    "    # your code\n",
    "\n",
    "    # ====\n",
    "\n",
    "\n",
    "def test_get_distance():\n",
    "    mu_x = torch.ones(3)\n",
    "    mu_y = torch.ones(3) * 10\n",
    "    sigma_x = torch.eye(3) * 5\n",
    "    sigma_y = torch.eye(3) * 3\n",
    "    dist = get_distance(mu_x, mu_y, sigma_x, sigma_y)\n",
    "    assert np.isclose(dist, 243.7621)\n",
    "\n",
    "\n",
    "test_get_distance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pduycMPbaiP"
   },
   "source": [
    "Let implement the function which calculate intermediate representations for real and fake samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6NZymnDbazC"
   },
   "outputs": [],
   "source": [
    "def get_features(\n",
    "    generator: object,\n",
    "    inception_model: object,\n",
    "    loader: object,\n",
    "    n_samples: int,\n",
    "    batch_size: int,\n",
    ") -> tuple:\n",
    "    if USE_CUDA:\n",
    "        generator = generator.cuda()\n",
    "        inception_model.cuda()\n",
    "\n",
    "    generator.eval()\n",
    "    inception_model.eval()\n",
    "\n",
    "    fake_features_list = []\n",
    "    real_features_list = []\n",
    "    cur_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_samples in loader:\n",
    "            # real_samples = resize_tensor(real_samples, image_size)\n",
    "            if USE_CUDA:\n",
    "                real_samples = real_samples.cuda()\n",
    "            # ====\n",
    "            # your code\n",
    "            # get features of real samples\n",
    "            # drow the w and h dimensions of the obtained features\n",
    "\n",
    "            # ====\n",
    "            # print(real_features.shape)\n",
    "            real_features_list.append(real_features)\n",
    "\n",
    "            fake_samples = generator.sample(len(real_samples), step=3)\n",
    "            # fake_samples = resize_tensor(fake_samples, image_size)\n",
    "            if USE_CUDA:\n",
    "                fake_samples = fake_samples.cuda()\n",
    "            # ====\n",
    "            # your code\n",
    "            # get features of fake samples\n",
    "            # drop the w and h dimensions of the the obtained features\n",
    "\n",
    "            # ====\n",
    "            fake_features_list.append(fake_features)\n",
    "\n",
    "            cur_samples += len(real_samples)\n",
    "            if cur_samples >= n_samples:\n",
    "                break\n",
    "\n",
    "    fake_features_all = torch.cat(fake_features_list)\n",
    "    real_features_all = torch.cat(real_features_list)\n",
    "    return fake_features_all, real_features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf4mQUnQbdPD"
   },
   "outputs": [],
   "source": [
    "# this is a helper function, do not change\n",
    "def calculate_stats(fake_features: torch.Tensor, real_features: torch.Tensor) -> tuple:\n",
    "    def get_covariance(features):\n",
    "        return torch.Tensor(np.cov(features.detach().numpy(), rowvar=False))\n",
    "\n",
    "    mu_fake = fake_features.mean(0)\n",
    "    mu_real = real_features.mean(0)\n",
    "    sigma_fake = get_covariance(fake_features)\n",
    "    sigma_real = get_covariance(real_features)\n",
    "    return mu_fake, mu_real, sigma_fake, sigma_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm8Ec8TCbfdS"
   },
   "source": [
    "Now we are ready to implement the main function for getting FID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaJzbGZRbfuK"
   },
   "outputs": [],
   "source": [
    "def get_frechet_inception_distance(\n",
    "    generator: object,\n",
    "    inception_model: object,\n",
    "    loader: object,\n",
    "    n_samples: int,\n",
    "    batch_size: int,\n",
    ") -> torch.Tensor:\n",
    "    # ====\n",
    "    # your code\n",
    "    # 1) get features\n",
    "    # 2) calculate stats\n",
    "    # 3) get distance\n",
    "\n",
    "    # ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oReQlX2KbmEa"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 10000  # number of samples in the cifar10 test dataset\n",
    "BATCH_SIZE = 16  # samples per iteration\n",
    "\n",
    "gt_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "FID_r1 = get_frechet_inception_distance(\n",
    "    generator=stylegan_r1,\n",
    "    inception_model=inception_model_act4,\n",
    "    loader=gt_loader,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "FID_wgangp = get_frechet_inception_distance(\n",
    "    generator=stylegan_wgangp,\n",
    "    inception_model=inception_model_act4,\n",
    "    loader=gt_loader,\n",
    "    n_samples=N_SAMPLES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAkSy47nbnfS"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(FID_r1, 48.35, atol=0.2)\n",
    "assert np.allclose(FID_wgangp, 48.4, atol=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0yUXYD1boyw"
   },
   "source": [
    "**In case you have free time**: You are free to evaluate the models from the previous homework via FID-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQVteW4bbo9L"
   },
   "outputs": [],
   "source": [
    "# FID scores of your nice models which beat StyleGAN\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a27a6a947b9464687ab7bbec5c2587c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "161ea9dc2761433d9b09475393a619cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d7c451931d946e0b4ac2acd87c14a69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fde761fbb244952823d91172be573b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f59289c9d9f442d894ff6538950dc2a",
      "placeholder": "",
      "style": "IPY_MODEL_acaed6a5659845e7bb0d1e311a28e014",
      "value": " 20/20 [08:44&lt;00:00, 26.20s/it]"
     }
    },
    "30c80e78c1c94e1d82ce19f0c387918b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "375467f9c01c46a3bb200f471c04387c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60e85ebf0dc54d95aeca4bd64565e30a",
      "placeholder": "",
      "style": "IPY_MODEL_ff4e4d56637c49c9af31f385f8c3efa0",
      "value": " 30/30 [12:46&lt;00:00, 25.72s/it]"
     }
    },
    "39371959124c45d6b23ed4c396786b2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_935f5c3aed5b45589fadd155c39398ef",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_161ea9dc2761433d9b09475393a619cf",
      "value": 20
     }
    },
    "441cc3087298473f845a472ec3b433fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d21ad6973864ad99b8138837abf07b7",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a83a2a5e683245a6b2f6b4317ba088bc",
      "value": 30
     }
    },
    "46679df9cef2458e8d9f89ca48b8bb1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47b504291ac142c6810d2455e7ba640b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52adbf79e43e4a75812b1971e1ec42c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0bb17fd40394cf780c5f3ab7d50e67f",
       "IPY_MODEL_39371959124c45d6b23ed4c396786b2d",
       "IPY_MODEL_5843f6c63f3447309428dddfee56cfeb"
      ],
      "layout": "IPY_MODEL_5edbc7bb89844306bedd81f02822ebd0"
     }
    },
    "5843f6c63f3447309428dddfee56cfeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83f883cda4a54d2080a7eb688c6dde5c",
      "placeholder": "",
      "style": "IPY_MODEL_1d7c451931d946e0b4ac2acd87c14a69",
      "value": " 20/20 [13:14&lt;00:00, 39.70s/it]"
     }
    },
    "5a68715ee62345fb92e472162e8d6853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5edbc7bb89844306bedd81f02822ebd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60e85ebf0dc54d95aeca4bd64565e30a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65b5df8489aa40748b6ea20e6fb9b19d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f59289c9d9f442d894ff6538950dc2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70d3ba49645049e39b4788ca2824abec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91fd48b2c517440ab78e1408b78a6610",
       "IPY_MODEL_97a21761bf48493e9df150cd0c092ee3",
       "IPY_MODEL_2fde761fbb244952823d91172be573b7"
      ],
      "layout": "IPY_MODEL_5a68715ee62345fb92e472162e8d6853"
     }
    },
    "7d21ad6973864ad99b8138837abf07b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83f883cda4a54d2080a7eb688c6dde5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91fd48b2c517440ab78e1408b78a6610": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46679df9cef2458e8d9f89ca48b8bb1e",
      "placeholder": "",
      "style": "IPY_MODEL_30c80e78c1c94e1d82ce19f0c387918b",
      "value": "100%"
     }
    },
    "935f5c3aed5b45589fadd155c39398ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97a21761bf48493e9df150cd0c092ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ea1673c51134ece8227b0eeb2cdefd9",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a27a6a947b9464687ab7bbec5c2587c",
      "value": 20
     }
    },
    "9ea1673c51134ece8227b0eeb2cdefd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0bb17fd40394cf780c5f3ab7d50e67f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea309d7a822141ef862de2080e315fd0",
      "placeholder": "",
      "style": "IPY_MODEL_47b504291ac142c6810d2455e7ba640b",
      "value": "100%"
     }
    },
    "a83a2a5e683245a6b2f6b4317ba088bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "acaed6a5659845e7bb0d1e311a28e014": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c74150b42e2b4f7b9954acff3f7c7db2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d05d064e93e04b5e85ccea618bfd44de",
       "IPY_MODEL_441cc3087298473f845a472ec3b433fa",
       "IPY_MODEL_375467f9c01c46a3bb200f471c04387c"
      ],
      "layout": "IPY_MODEL_65b5df8489aa40748b6ea20e6fb9b19d"
     }
    },
    "d05d064e93e04b5e85ccea618bfd44de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4d76da3a8f44c9b96a8835730dab334",
      "placeholder": "",
      "style": "IPY_MODEL_d2280cc997464b608898a04cce98c617",
      "value": "100%"
     }
    },
    "d2280cc997464b608898a04cce98c617": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea309d7a822141ef862de2080e315fd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4d76da3a8f44c9b96a8835730dab334": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff4e4d56637c49c9af31f385f8c3efa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
